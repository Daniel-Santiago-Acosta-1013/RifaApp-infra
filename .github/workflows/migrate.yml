name: Run Database Migrations

on:
  workflow_dispatch:
    inputs:
      backend_ref:
        description: "Ref del backend para calcular el schema hash (branch o tag). Opcional."
        required: false
        type: string

env:
  AWS_REGION: ${{ vars.AWS_REGION || 'us-east-1' }}
  BACKEND_REPO: ${{ vars.BACKEND_REPO }}
  BACKEND_REF: ${{ inputs.backend_ref || vars.BACKEND_REF || 'main' }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  TF_IN_AUTOMATION: "true"
  TF_INPUT: "false"
  TG_NON_INTERACTIVE: "true"
  API_BASE_URL: ${{ vars.API_BASE_URL }}

jobs:
  migrate:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout infra
        uses: actions/checkout@v4

      - name: Validate backend repo
        run: |
          if [ -z "$BACKEND_REPO" ]; then
            echo "BACKEND_REPO is not set. Configure it as a repo variable." >&2
            exit 1
          fi

      - name: Checkout backend
        uses: actions/checkout@v4
        with:
          repository: ${{ env.BACKEND_REPO }}
          ref: ${{ env.BACKEND_REF }}
          path: backend

      - name: Compute schema hash
        id: schema
        working-directory: backend
        run: |
          python3 - <<'PY' > /tmp/schema_hash.txt
          import hashlib
          from pathlib import Path
          
          root = Path(".")
          plan = root / "sqitch.plan"
          deploy_dir = root / "sqitch" / "deploy"
          
          if not plan.exists():
            raise SystemExit("sqitch.plan not found for schema hash")
          if not deploy_dir.exists():
            raise SystemExit("sqitch/deploy not found for schema hash")
          
          h = hashlib.sha256()
          h.update(plan.read_bytes())
          for path in sorted(deploy_dir.glob("*.sql")):
            h.update(path.name.encode("utf-8"))
            h.update(b"\0")
            h.update(path.read_bytes())
          
          print(h.hexdigest())
          PY

          SCHEMA_HASH="$(cat /tmp/schema_hash.txt | tr -d '\n')"
          if [ -z "$SCHEMA_HASH" ]; then
            echo "Failed to compute schema hash." >&2
            exit 1
          fi
          echo "schema_hash=$SCHEMA_HASH" >> "$GITHUB_OUTPUT"

      - name: Resolve DB metadata prefix
        id: db_meta
        run: |
          python3 - <<'PY' > /tmp/db_meta.json
          import json
          from pathlib import Path

          defaults = {
              "project_name": "rifaapp",
              "environment": "dev",
          }

          data = dict(defaults)
          tfvars = Path("envs/dev/terraform.tfvars")
          if tfvars.exists():
              for line in tfvars.read_text(encoding="utf-8").splitlines():
                  line = line.strip()
                  if not line or line.startswith("#") or "=" not in line:
                      continue
                  key, value = line.split("=", 1)
                  key = key.strip()
                  value = value.strip().strip('"')
                  data[key] = value

          project = data.get("project_name", defaults["project_name"])
          env = data.get("environment", defaults["environment"])
          prefix = f"/{project}/{env}/db"

          with open("/tmp/db_meta.json", "w", encoding="utf-8") as handle:
              json.dump({"prefix": prefix}, handle)
          PY

          DB_META_PREFIX="$(python3 -c 'import json; print(json.load(open("/tmp/db_meta.json","r",encoding="utf-8"))["prefix"])')"
          if [ -z "$DB_META_PREFIX" ]; then
            echo "Failed to resolve DB metadata prefix." >&2
            exit 1
          fi
          echo "db_meta_prefix=$DB_META_PREFIX" >> "$GITHUB_OUTPUT"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Fetch schema metadata
        id: schema_meta
        run: |
          set -euo pipefail
          DB_META_PREFIX="${{ steps.db_meta.outputs.db_meta_prefix }}"
          if [ -z "$DB_META_PREFIX" ]; then
            echo "DB metadata prefix is empty." >&2
            exit 1
          fi

          get_param() {
            local name="$1"
            local value=""
            set +e
            value="$(aws ssm get-parameter --name "$name" --query 'Parameter.Value' --output text 2>/tmp/ssm_err)"
            status=$?
            set -e
            if [ $status -ne 0 ]; then
              if grep -q "ParameterNotFound" /tmp/ssm_err; then
                echo ""
                return 0
              fi
              cat /tmp/ssm_err >&2 || true
              exit 1
            fi
            echo "$value"
          }

          current_hash="$(get_param "$DB_META_PREFIX/schema_hash")"
          snapshot_hash="$(get_param "$DB_META_PREFIX/snapshot_hash")"
          snapshot_id="$(get_param "$DB_META_PREFIX/snapshot_id")"

          echo "current_hash=$current_hash" >> "$GITHUB_OUTPUT"
          echo "snapshot_hash=$snapshot_hash" >> "$GITHUB_OUTPUT"
          echo "snapshot_id=$snapshot_id" >> "$GITHUB_OUTPUT"

      - name: Create pre-migration snapshot when schema changes
        id: snapshot
        env:
          TARGET_SCHEMA_HASH: ${{ steps.schema.outputs.schema_hash }}
          CURRENT_SCHEMA_HASH: ${{ steps.schema_meta.outputs.current_hash }}
        run: |
          set -euo pipefail
          DB_META_PREFIX="${{ steps.db_meta.outputs.db_meta_prefix }}"
          if [ -z "$DB_META_PREFIX" ]; then
            echo "DB metadata prefix is empty." >&2
            exit 1
          fi

          if [ -z "$CURRENT_SCHEMA_HASH" ]; then
            echo "No current schema hash. Skipping snapshot."
            echo "snapshot_created=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          if [ "$CURRENT_SCHEMA_HASH" = "$TARGET_SCHEMA_HASH" ]; then
            echo "Schema hash unchanged. Skipping snapshot."
            echo "snapshot_created=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          python3 - <<'PY' > /tmp/db_meta.json
          import json
          from pathlib import Path
          
          defaults = {
              "project_name": "rifaapp",
              "environment": "dev",
          }
          
          data = dict(defaults)
          tfvars = Path("envs/dev/terraform.tfvars")
          if tfvars.exists():
              for line in tfvars.read_text(encoding="utf-8").splitlines():
                  line = line.strip()
                  if not line or line.startswith("#") or "=" not in line:
                      continue
                  key, value = line.split("=", 1)
                  key = key.strip()
                  value = value.strip().strip('"')
                  data[key] = value
          
          project = data.get("project_name", defaults["project_name"])
          env = data.get("environment", defaults["environment"])
          cluster_id = f"{project}-{env}-aurora"
          
          with open("/tmp/db_meta.json", "w", encoding="utf-8") as handle:
              json.dump({"cluster_id": cluster_id}, handle)
          PY

          CLUSTER_ID="$(python3 -c 'import json; print(json.load(open("/tmp/db_meta.json","r",encoding="utf-8"))["cluster_id"])')"

          if [ -z "$CLUSTER_ID" ]; then
            echo "Failed to resolve DB cluster identifier." >&2
            exit 1
          fi

          SNAPSHOT_ID="${CLUSTER_ID}-pre-migration-$(date -u +%Y%m%d%H%M%S)"
          echo "Creating snapshot $SNAPSHOT_ID for cluster $CLUSTER_ID"

          aws rds create-db-cluster-snapshot \
            --db-cluster-identifier "$CLUSTER_ID" \
            --db-cluster-snapshot-identifier "$SNAPSHOT_ID" >/dev/null

          aws rds wait db-cluster-snapshot-available \
            --db-cluster-snapshot-identifier "$SNAPSHOT_ID"

          aws ssm put-parameter \
            --name "$DB_META_PREFIX/snapshot_id" \
            --value "$SNAPSHOT_ID" \
            --type String \
            --overwrite >/dev/null

          aws ssm put-parameter \
            --name "$DB_META_PREFIX/snapshot_hash" \
            --value "$CURRENT_SCHEMA_HASH" \
            --type String \
            --overwrite >/dev/null
          echo "snapshot_created=true" >> "$GITHUB_OUTPUT"
          echo "snapshot_id=$SNAPSHOT_ID" >> "$GITHUB_OUTPUT"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.7

      - name: Install Terragrunt
        run: |
          TERRAGRUNT_VERSION="0.96.1"
          curl -sSL -o terragrunt "https://github.com/gruntwork-io/terragrunt/releases/download/v${TERRAGRUNT_VERSION}/terragrunt_linux_amd64"
          chmod +x terragrunt
          sudo mv terragrunt /usr/local/bin/terragrunt

      - name: Resolve API base URL
        id: api
        working-directory: envs/dev
        run: |
          if [ -n "$API_BASE_URL" ]; then
            echo "api_base_url=$API_BASE_URL" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          terragrunt init
          terragrunt output -json > /tmp/tg_output.json

          API_BASE_URL=$(python3 - <<'PY'
          import json
          import sys
          
          with open("/tmp/tg_output.json", "r", encoding="utf-8") as handle:
              data = json.load(handle)
          
          value = data.get("api_base_url", {}).get("value", "")
          print(value)
          PY
          )

          if [ -z "$API_BASE_URL" ]; then
            echo "api_base_url output not found." >&2
            exit 1
          fi

          echo "api_base_url=$API_BASE_URL" >> "$GITHUB_OUTPUT"

      - name: Run migrations
        env:
          API_BASE_URL: ${{ steps.api.outputs.api_base_url }}
        run: |
          if [ -z "$API_BASE_URL" ]; then
            echo "API base URL is empty." >&2
            exit 1
          fi

          API_BASE_URL="${API_BASE_URL%/}"
          curl -sS -f -X POST \
            -H "Accept: application/json" \
            "$API_BASE_URL/migrations/run"

      - name: Persist schema hash after migrations
        env:
          TARGET_SCHEMA_HASH: ${{ steps.schema.outputs.schema_hash }}
        run: |
          set -euo pipefail
          if [ -z "$TARGET_SCHEMA_HASH" ]; then
            echo "TARGET_SCHEMA_HASH is empty." >&2
            exit 1
          fi
          DB_META_PREFIX="${{ steps.db_meta.outputs.db_meta_prefix }}"
          if [ -z "$DB_META_PREFIX" ]; then
            echo "DB metadata prefix is empty." >&2
            exit 1
          fi

          aws ssm put-parameter \
            --name "$DB_META_PREFIX/schema_hash" \
            --value "$TARGET_SCHEMA_HASH" \
            --type String \
            --overwrite >/dev/null

      - name: Delete previous snapshot (cost control)
        if: steps.snapshot.outputs.snapshot_created == 'true'
        env:
          OLD_SNAPSHOT_ID: ${{ steps.schema_meta.outputs.snapshot_id }}
          NEW_SNAPSHOT_ID: ${{ steps.snapshot.outputs.snapshot_id }}
        run: |
          set -euo pipefail
          if [ -z "$OLD_SNAPSHOT_ID" ]; then
            echo "No previous snapshot to delete."
            exit 0
          fi

          if [ "$OLD_SNAPSHOT_ID" = "$NEW_SNAPSHOT_ID" ]; then
            echo "Previous snapshot matches new snapshot; nothing to delete."
            exit 0
          fi

          echo "Deleting previous snapshot $OLD_SNAPSHOT_ID"
          aws rds delete-db-cluster-snapshot \
            --db-cluster-snapshot-identifier "$OLD_SNAPSHOT_ID" >/dev/null
